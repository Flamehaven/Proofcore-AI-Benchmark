# ================================================================
# ProofCore v1.0.0 - Environment Configuration
# ================================================================
# This file contains all environment variables for ProofCore.
# Copy this file to .env and configure for your environment.
#
# [REQUIRED] = Must be set for application to function
# [OPTIONAL] = Application will work without it (uses defaults)
# [DEVELOPMENT] = Only needed in development mode
# [PRODUCTION] = Only needed in production deployments
#
# ================================================================
# FRONTEND CONFIGURATION (Vite)
# ================================================================

# API Base URL for backend communication [OPTIONAL]
# Default: http://localhost:3001/api/v1
# Used by frontend to connect to backend verification service
# Set to empty string to use browser-only verification (offline mode)
VITE_API_BASE_URL=http://localhost:3001/api/v1

# API Key for backend authentication [OPTIONAL]
# Default: (empty - not required for offline mode)
# Generate: python -c "import secrets; print(secrets.token_urlsafe(32))"
VITE_API_KEY=

# API Request timeout in milliseconds [OPTIONAL]
# Default: 30000 (30 seconds)
# Timeout for backend API calls
VITE_API_TIMEOUT=30000

# API Mode selection [OPTIONAL]
# Options: mock, development, production
# - mock: Use in-memory data (development testing)
# - development: Connect to local backend
# - production: Connect to production backend
# Default: mock
VITE_API_MODE=mock

# Enable debug logging [OPTIONAL]
# Options: true, false
# Default: false
VITE_API_DEBUG=false

# ================================================================
# LLM PROVIDER API KEYS (OPTIONAL)
# ================================================================
# LLM integration is OPTIONAL for ProofCore v1.0.0
# Application works completely offline without these keys.
# Uncomment and set these only if you want multi-LLM semantic evaluation.
#
# Offline Mode (Default):
# - Uses heuristic scoring (detects vague language, logical structure)
# - High confidence, no API latency
# - Perfect for offline/classroom use
#
# Online Mode (Optional):
# - Calls OpenAI, Anthropic, and/or Google APIs in parallel
# - Higher accuracy with LLM understanding
# - Requires at least one API key below

# OpenAI API Key (optional) [OPTIONAL]
# Get your key at: https://platform.openai.com/api-keys
# Used models: gpt-4o-mini
# OPENAI_API_KEY=sk-...

# Anthropic API Key (optional) [OPTIONAL]
# Get your key at: https://console.anthropic.com/settings/keys
# Used models: claude-3-5-sonnet or claude-3-haiku
# ANTHROPIC_API_KEY=sk-ant-...

# Google Gemini API Key (optional) [OPTIONAL]
# Get your key at: https://makersuite.google.com/app/apikey
# Used models: gemini-1.5-flash or gemini-2.0-flash
# GOOGLE_API_KEY=AIza...

# LLM Configuration [OPTIONAL]
# Request timeout for LLM API calls (seconds)
# Default: 30
LLM_TIMEOUT=30

# Maximum retry attempts for failed LLM requests
# Default: 3
LLM_MAX_RETRIES=3

# ================================================================
# BACKEND CONFIGURATION (FastAPI)
# ================================================================

# Application settings [OPTIONAL]
# Application name and version
APP_NAME=ProofCore Backend
APP_VERSION=1.0.0

# Debug mode [OPTIONAL]
# Default: false
# Enable for detailed logging and error messages
DEBUG=false

# ================================================================
# DATABASE CONFIGURATION (Backend Only)
# ================================================================
# Database is OPTIONAL for ProofCore v1.0.0
# Application works without backend database (frontend-only mode)

# SQLite (for development) [OPTIONAL]
# Lightweight file-based database, no setup needed
# DATABASE_URL=sqlite+aiosqlite:///./proofcore.db

# PostgreSQL (for production) [OPTIONAL]
# Recommended for production deployments
# Syntax: postgresql+asyncpg://username:password@host:port/database
# Example: postgresql+asyncpg://proofcore:secure-password@db.example.com:5432/proofcore
# DATABASE_URL=postgresql+asyncpg://user:password@localhost:5432/proofcore

# ================================================================
# API CONFIGURATION (Backend Only)
# ================================================================

# API Version prefix [OPTIONAL]
# Default: /api/v1
API_V1_PREFIX=/api/v1

# CORS (Cross-Origin Resource Sharing) origins [OPTIONAL]
# Comma-separated list of allowed frontend URLs
# Default: http://localhost:5173,http://localhost:3000
# Production: https://proofcore.io,https://app.proofcore.io
CORS_ORIGINS=http://localhost:5173,http://localhost:3000

# API Key for client authentication [OPTIONAL]
# Generate: python -c "import secrets; print(secrets.token_urlsafe(32))"
# Used to authenticate API requests from frontend
API_KEY=your-secure-api-key-here

# Require API key for all requests [OPTIONAL]
# Default: false (for offline-first approach)
# Set to true in production to enforce authentication
REQUIRE_API_KEY=false

# ================================================================
# VERIFICATION ENGINE CONFIGURATION
# ================================================================

# Hybrid scoring weights (must sum to 1.0) [OPTIONAL]
# Symbolic verification weight
# Default: 0.7 (70% - rigorous mathematical verification)
SYMBOLIC_WEIGHT=0.7

# Semantic evaluation weight
# Default: 0.3 (30% - AI understanding of meaning)
SEMANTIC_WEIGHT=0.3

# Minimum score threshold for valid proofs [OPTIONAL]
# Range: 0-100
# Default: 70
# Proofs with score below this are considered invalid
PASS_THRESHOLD=70.0

# ================================================================
# PERFORMANCE TUNING
# ================================================================

# Maximum concurrent proof verifications [OPTIONAL]
# Default: 5
# Limit parallel verification operations
MAX_CONCURRENT_VERIFICATIONS=5

# Database connection pool size [OPTIONAL]
# Default: 10
# Number of persistent database connections
DB_POOL_SIZE=10

# Database connection pool overflow [OPTIONAL]
# Default: 20
# Additional temporary connections when pool is full
DB_MAX_OVERFLOW=20

# ================================================================
# SECURITY SETTINGS
# ================================================================

# Allowed hosts (comma-separated) [OPTIONAL]
# Hosts allowed to make API requests
# Default: localhost,127.0.0.1
# Production: proofcore.io,api.proofcore.io
ALLOWED_HOSTS=localhost,127.0.0.1

# Enable rate limiting [OPTIONAL]
# Default: false
# Set to true to limit requests per IP
ENABLE_RATE_LIMITING=false

# Rate limit: requests per minute [OPTIONAL]
# Default: 60
# Max requests allowed per IP address per minute
RATE_LIMIT_PER_MINUTE=60

# ================================================================
# LOGGING CONFIGURATION
# ================================================================

# Log level [OPTIONAL]
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Default: INFO
LOG_LEVEL=INFO

# Log format [OPTIONAL]
# Default: %(asctime)s - %(name)s - %(levelname)s - %(message)s
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s

# ================================================================
# FEATURE FLAGS
# ================================================================

# Enable/disable semantic verification (LLM evaluation) [OPTIONAL]
# Default: true
# Can be disabled to force offline heuristic mode
ENABLE_SEMANTIC_EVALUATION=true

# Enable/disable symbolic verification [OPTIONAL]
# Default: true
# Should always be true (core feature)
ENABLE_SYMBOLIC_VERIFICATION=true

# Enable/disable cost tracking for LLM APIs [OPTIONAL]
# Default: true
# Tracks API usage and costs
ENABLE_COST_TRACKING=true

# Enable/disable offline fallback mode [OPTIONAL]
# Default: true
# Use heuristic scoring when LLM APIs unavailable
ENABLE_OFFLINE_FALLBACK=true

# ================================================================
# DEVELOPMENT SETTINGS
# ================================================================

# Auto-reload on code changes [DEVELOPMENT ONLY] [OPTIONAL]
# Default: false
# Enable for development with auto-reload
RELOAD=false

# Create database tables on startup [DEVELOPMENT ONLY] [OPTIONAL]
# Default: true
# Auto-create schema if tables don't exist
AUTO_CREATE_TABLES=true

# Populate sample data [DEVELOPMENT ONLY] [OPTIONAL]
# Default: false
# Load example proofs for testing
POPULATE_SAMPLE_DATA=false

# ================================================================
# DEPLOYMENT SETTINGS
# ================================================================

# Environment type [OPTIONAL]
# Options: development, staging, production
# Default: development
NODE_ENV=development

# Port for backend server [OPTIONAL]
# Default: 3001
# HTTP port for FastAPI server
PORT=3001

# Frontend port (Vite dev server) [OPTIONAL]
# Default: 5173
VITE_PORT=5173

# ================================================================
# OFFLINE-FIRST CONFIGURATION
# ================================================================
# ProofCore is built for offline-first operation.
# All features below enable gradual enhancement with optional services.

# Enable offline-first mode [OPTIONAL]
# Default: true
# Works completely without backend or LLM APIs
OFFLINE_FIRST=true

# Cache proof results locally [OPTIONAL]
# Default: true
# Store verification results in browser storage
ENABLE_LOCAL_CACHE=true

# Sync cache to backend when available [OPTIONAL]
# Default: true
# Upload cached proofs to backend for persistence
ENABLE_CACHE_SYNC=true

# ================================================================
# QUICK START GUIDE
# ================================================================
#
# For Offline-First (Recommended for v1.0.0):
# - No additional configuration needed
# - All defaults work for offline mode
# - Copy this file as .env and run `npm run dev`
#
# For Local Development with Backend:
# - Set VITE_API_BASE_URL=http://localhost:3001/api/v1
# - Set VITE_API_MODE=development
# - Run: `docker-compose up -d` (starts PostgreSQL)
# - Run: `npm run dev` (frontend)
# - Run: `python -m uvicorn backend.main:app --reload` (backend)
#
# For Production with LLM Integration:
# - Set OPENAI_API_KEY=sk-...
# - Set ANTHROPIC_API_KEY=sk-ant-...
# - Set VITE_API_MODE=production
# - Set NODE_ENV=production
# - Configure CORS_ORIGINS to production domains
# - Use environment variables for sensitive values
#
# ================================================================
